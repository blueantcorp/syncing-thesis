
\section{Architecture of Histo}
\label{sec:main.histo}

Based on the requirements and the evaluation of CouchDB we derive a new architecture for a practical synchronization solution.

\begin{itemize}
\item
  \textbf{No Timestamps}: history-based 3-way merging
\item
  \textbf{No Change Tracing}: explicit change tracing is not necessary - support
  diff computation on the fly
\item
  \textbf{Data Agnostic}: leave diff and merge of the actual data to
  plugins
\item
  \textbf{Distributed}: synchronization does not require a central server
\item
  \textbf{Functional Design}: only implement the functional parts of synchronization - leave everything else to the application (transport, persistence)
\item
  \textbf{Sensitive Defaults}: have defaults that `just work' but
  still support custom logic (e.g. for conflict resolution)
\item
  \textbf{Cross-Platform}: be available on every major platform through the use of Web Standards
\end{itemize}

\section{Differencing and Merging of Models}
As described in section \ref{sec:background.definition} synchronization always starts with an update detection phase.
One our our design goals is to relieve the application developer from manual change tracing.
We therefore need to implement a differencing algorithm for the types of models described in section \ref{sec:main.requirements.data-models}.\\
The meta model definition in the form of entities, their attributes and relationships does not have to be synchronized as it should be part of the application code.
We have to focus on synchronizing the actual data which is structured through entity instances, their attribute values and relationships to other instances.
Most modern web application frameworks realize one-to-one relationships by simply having an attribute storing the related instance's ID.
One-to-many relationships are realized through an attribute having a collection of 
instance IDs.\\
Instance collections often have a relevant order that needs to be preserved.
An example is the list of tasks in a project that is displayed to the user.
The user wants to be able to change the order of tasks and the order should be persisted.\\
Summarizing the kind of structures we need to synchronize:

\begin{itemize}
\item Instances with their attribute values
\item Attribute values that can be literals or instance IDs (modeling one-to-one relations)
\item Attribute values that can be ordered collections (modeling one-to-many relations)
\end{itemize}

To show correctness of a differencing algorithm we need to define sample model states with expected differencing results.
Based on an ancestor state all users start with we define several possible branch states.
For each branch state we will define the difference to the ancestor state.
This set of data can then be used as a test case for our implementation.\\

Our ancestor state:\\

\begin{tabular}{ l l l l }
\multicolumn{4}{ c }{Projects} \\
ID & Project Name & Members & Tasks \\
\hline
1 & Marketing Material & Rita, Tom, Allen & 1, 2, 3, 4 \\
2 & Product Roadmap & Rita, Allen & 5 \\
\end{tabular} \\

`Members' is an unordered collection of users - we define the user's IDs identical to their names.\\
`Tasks' is an ordered collection of tasks IDs.\\

\begin{tabular}{ l l l l l }
\multicolumn{5}{ c }{Tasks} \\
ID & Title & Due Date & Assignee & Done \\
\hline
1 & Create event poster & 2013-08-12 & Rita & No \\
2 & Write blog entry on event & 2013-07-20 & Tom & No \\
3 & Prepare field study & 2013-07-22 & Rita & No \\
4 & Call partner agencies & 2013-07-22 & Rita & No \\
5 & Update priority sheet & 2013-07-13 & Allen & No
\end{tabular} \\

TODO:

- explain diff, merge and patch

- implement diff, merge and patch logic for primitive data structures
  -> use them to recursively model complex data structures

- ensure conflicts are made explicit

\subsection{Sets}
\subsection{Ordered Lists}
\subsection{Ordered Sets}
\subsection{Dictionaries}
used for object collections in data models

\subsection{Ordered Dictionaries}
most common for managing ordered object collections in data models

can be modeled with dictionary and ordered set/list
\subsection{Trees}
- tree as an example for composite data model

- efficient child tree pointers like in git

\subsection{Models}
- show how to represent complex data models by combining the data structures above

- instances are key-value sets

- collections are ordered sets

- take ordered-list diff as granted

\section{Storing and Commiting Changes}
\label{main.committing}
As syncing is state based we need to track the history of edits on each client.\\Each client has his own replica of the database and commits
data locally.\\On every commit we create a commit object that links both
to the new version of the data and the previous commit.\\

TODO:

- use content-adressable store

- only store changes and reference unchanged data through hashs --> like git

- commit links to data and parent commit

\section{Differencing Across Commits}
\label{main.diff-across-commits}

TODO:

- Most Recent Common Ancestor algorithm used for finding common commit of clients

- walk commit graph until LCA

- recursive application of LCA on every fork in graph

- implementation as separate module

- use per-commit diff to find full data diff across commits

\section{Synchronization Protocol}
Synchronization always happens from a \emph{Source} node to a \emph{Target} node.
If it is run simultaneously with Source and Target exchanged, it keeps both nodes in sync with each other.\\
The algorithm is designed to be able to run independently of the Source or Target.
It could be implemented as a separate application possibly even running on a different device - as long as it has access to both the Source and Target node.\\
The Synchronizer could be run in regular intervals or explicitly triggered by changes in the Source node.\\

The latest commit on a node we refer to as the \emph{head}.
A node has a \emph{master head} which refers to the version of the data considered to be `true' by the node.\\
For each remote node it synchronizes with, the node keeps a \emph{remote tracking head}.\\
A remote tracking head represents what the local node considers to be the current state of a remote node.

Synchronization follows a two-step protocol, step one propagates all changed data from Source to Target, step two executes a local merge operation.

\subsubsection{Propagation}
Propagation follows the following protocol:

\begin{enumerate}
\item Read all commit IDs since the last synced commit from Source and write them to Target.
\item Let the Target compute the common ancestor commit ID of Target's and Source's master heads.
\item Read all changed data since the common ancestor commit from Source and write to Target.
\item Set the Target's remote tracking head of Source to Source's master head.
\end{enumerate}

Once these steps are executed, the Target node has the current state of Source available locally.\\
The Target's head still refers to the same state as the Source data has not been merged.\\

Listing \ref{propagation-protocol} summarizes the protocol as pseudo-code.

\begin{lstlisting}[caption=Propagation Protocol, label=propagation-protocol]

commitIDsSource = source.getCommitIDsSince(lastSyncedCommit)

target.writeCommitIDs(commitIDsSource)

commonAncestor = target.getCommonAncestor(target.head.master, source.head.master)

changedData = source.getChangedDataSince(commonAncestor)

target.writeData(changedData)

\end{lstlisting}

The functions `getCommitIDsSince()' and `getChangedDataSince()' are implemented as described in section \ref{main.diff-across-commits}.\\
The most recent common ancestor algorithm used in `getCommonAncestor()' is described in section \ref{background.mrca}.\\
The internals used by `writeData()' and the underlying commit data model are explained in section \ref{main.committing}.

\subsubsection{Merging}
Even if the Source is disconnected at this stage, the Target has all the necessary information to process the merge offline:\\

\begin{itemize}
\item The Target's master head we refer to as the \emph{master head}.\\
\item The Target's remote tracking branch for the Source we refer to as the \emph{Source tracking head}.
\end{itemize}

\begin{enumerate}
\item Compute the common ancestor of the master head and the Source tracking head. (The common ancestor could also be re-used from the propagation step.)
\item If the common ancestor equals the Source tracking head:\\
  The Source has not changed since the last synchronization. The master head is ahead of the Source tracking head.\\
  The algorithm can stop here.
\item If the common ancestor equals the master head:\\
  The Target has not changed since the last synchronization.\\
  The Source's head is ahead of Target.\\
  We can fast-forward the master head to the Source tracking head.
\item If the common ancestor is neither the Source tracking head nor the master head:\\
  Both Source and Target must have changed data since the last synchronization.\\
  We run a three-way merge of the common ancestor, Source tracking head and master head.\\
  We commit the result as the new master head.
\end{enumerate}

This protocol is able to minimize the amount of data sent between synced
stores even in a distributed, peer-to-peer setting.\\

Updating the Target's head uses optimistic locking.
To update the head you need to include the last read head in your request.
So both the fast-forward operation or the commit of a merge result can be rejected if the Target has been updated in the meantime.
If this happens the Synchronizer simply has to re-run the merge algorithm.\\

The merging process can be described in pseudo-code as shown in figure \ref{merging-protocol}.

\begin{lstlisting}[caption=Merging Protocol, label=merging-protocol]

masterHead = target.head.master
sourceTrackingHead = target.head.sourceID

commonAncestor = target.getCommonAncestor(masterHead, sourceTrackingHead)

if (commonAncestor == sourceTrackingHead) {
  // do nothing

} else if (commonAncestor == masterHead) {
  // fast-forward master head
  try {
    // when updating the head we have to pass in the previous head:
    target.setHead(sourceTrackingHead, masterHead)
  } catch {
    // the master head has been updated in the meantime
    // start over
  }

} else {
  commonAncestorData = target.getData(commonAncestor)
  sourceHeadData = target.getData(sourceTrackingHead)
  targetHeadData = target.getData(masterHead)

  mergedData = three-way-merge(commonAncestorData, sourceHeadData, targetHeadData)

  // commit object linking commit data with its ancestors:
  commitObject = createCommit(mergedData, [masterHead, sourceTrackingHead])

  try {
    // when updating the head we have to pass in the previous head:
    target.commit(commitObject, masterHead)    
  } catch {
    // the master head has been updated in the meantime
    // start over
  }
}

\end{lstlisting}

\section{Handling Conflicts}

TODO:

- application specific, no general solution

- automatic resolution strategies

- manual resolution through user

\section{Synchronization Topologies}

TODO:

- document different supported topologies

- client-server

- client-client

- client-server + server-server

- hierarchical (office server + cloud server)

\section{Optimizations}

TODO:

- Only keep limited history.

- Clients who are disconnected for too long have to fetch redundant data.

- Ideal case: remember until oldest head of nodes.

\section{Integration with Application Logic}

TODO:

- demonstrate how to interface with standard MVC frameworks like Backbone, Ember.js, Angular
