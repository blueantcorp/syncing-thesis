
\chapter{Background}\label{background}

We will start by defining some consistent terminology used throughout the thesis:

\begin{itemize}
\item \emph{Synchronization engine}: A framework that manages functional aspects of data synchronization we call a synchronization engine.
\item \emph{Node}: A node represents a single instance of an application connected to other nodes for synchronization purposes. It could be a mobile device or a server connecting devices.
\item \emph{Synchronization protocol}: The core part of a synchronization engine that describes the communication between nodes in a synchronization engine.
\item \emph{Offline}: A node is offline if it is partitioned from the network.
\item \emph{Object}: Objects can represent any kind of data like files or entities. Objects can be composed of \emph{parts} like lines (for files) or attributes (for entities).
\item \emph{Atom}: An atom is an object that can not be divided into parts. Examples are a line in a file or literal attributes like strings or numbers in an entity.
\end{itemize}

Most synchronization algorithms can be divided into three major components.
\begin{enumerate}
\item \emph{Update Detection} refers to the process of identifying changes to the data on each client.
If updates are  stored explicitly we categorize the algorithm as \emph{edit-based} which applies to most \emph{stream-based} approaches.
\emph{State based} synchronization usually run a differencing algorithm on each synchronization operation to detect updates.
\item \emph{Update Propagation} describes the algorithm's component which implements the propagation protocol among the synchronizing clients.
The design of the propagation protocol eventually defines which kinds of network topologies the algorithm can support.
\item \emph{Reconciliation} is the final phase where the client updates are merged and conflicts identified.
In a centralized scenario this part is usually carried by the server.
Distributed architectures supporting peer-to-peer synchronization are much more complex as all clients have to reconcile the received updates in an eventually consistent way.
\end{enumerate}

\section{Stream-Based Synchronization}
An application that tracks each edit and sends it in a stream to remote nodes follows a stream-based synchronization protocol.
Stream-based synchronization is very common among real-time document editors like Google Docs.\\

An edit usually represents an insert or delete operation at a certain position in the text.
These edit operations are broadcasted to remote nodes and then ``replayed''.
As participating nodes can concurrently edit a document the stream of edit operations can not just be applied without modifications.\\
The combination of local modifications and received edit operations from a remote node requires the transformation of the remote operations in order to be correctly applied.\\
The family of algorithms developed to correctly transform the edit operations is described as \emph{Operational Transformation} \cite{Ellis:1998vf}.\\
If some nodes are temporarily offline while continuing to edit, the correct transformation of many concurrent edit operations becomes very complex and error-prone.\\
A practical problem in modern user interfaces is that it is hard to correctly capture all edits made to data.
If a single edit is missed the result is a fork possibly rendering all future update operations as incorrect.
Packet loss due to unreliable network connections have also be taken into account which further complicates the design of a robust algorithm.\\
Research has therefore investigated options for data synchronization that do not require Operational Transformation.\\

\emph{Commutative Replicated Data Types} (CRDTs) have emerged as a viable alternative for specific use cases.
A recent study by Shapiro et. al presents a range of data types designed for synchronization without concurrency control \cite{Shapiro:2011wy}.\\
CRDTs are designed in a way that all edit operations commute when applied in causal order.
Due to the restrictions on supported operations on data types, CRDTs are only applicable in a narrow set of scenarios.

\section{History-Based Synchronization}
Snapshot-based methods work by tracking and relating an application's data state over time.
Instead of sending a sequential stream of raw updates, each client collects additional meta-data that allows more complex reasoning about the state of each client.\\
A prominent example is the distributed content tracking system \emph{git} \cite{git} which can resolve the most complex peer-to-peer synchronization scenarios.\\
Git achieves this by storing the entire history of a project's database on each client.
Each edit made to objects in the database is stored as a commit object and related to its ancestors.\\
Through the resulting commit graph each client can identify the exact subset of updates each remote node has to receive in order to be in sync.\\
While it sounds extremely inefficient to store the entire history of a database, git manages to do this in a very efficient way through a \emph{Content Addressable Store} and data compression.
It is not uncommon that the uncompressed form of the current state of a git project is larger than the project's entire history.

\section{Three-Way Merging}
Three-way merging describes the concept for an algorithm that performs a merge operation on two objects based on a common ancestor.\\
Let \emph{A} be the initial state of the object and let \emph{B} and \emph{C} be edited versions of \emph{A}.
The goal is to merge \emph{B} and \emph{C} into a new object \emph{D}.\\
The merge algorithm starts by identifying the differences between \emph{A} and \emph{B} and between \emph{A} and \emph{C}.\\
All \emph{parts} of object \emph{B} that are neither changed in \emph{B} nor in \emph{C} are carried over into \emph{D}.\\
All changes to parts of the object in \emph{B} that have not been changed in \emph{C} are directly accepted and added to \emph{D}.\\
If the same parts are edited both in \emph{B} and \emph{C} we have a merge conflict that needs to be resolved.\\

Three-way merging only describes the general concept but the actual algorithm will differ based on the type of objects that are merged.
Text files are the most common type of object with lines seen as the \emph{parts}.
The unix program \emph{diff3} implements a three-way merge variant for text files \cite{diff3}.\\
Most modern version control systems implement three-way merging to allow lock-free collaboration on source code.
\emph{Git} applies three-way merging not only for text files but for entire file system trees \cite{git}.\\

Tancred Lindholm designed a three-way merging algorithm for XML-documents.
With the \emph{3DM} tool there is even an implementation available \cite{Lindholm:2001uv}.
As XML supports the expression of a broad range of data types this is probably one of the most generic implementations.

\section{Most Recent Common Ancestor}
- describe problem with graphs

- describe solution referring to standard algo

\section{Content Adressable Storage}
- copy on write

- simple verification of data, free checksums

- git as example

\section{HTML5 and Offline Applications}
HTML5 specifies a number of client-side storage options. Most are a work in process and still have to be adopted by all browser vendors. IndexedDB is most likely going to be the standard for building offline-capable web applications. Combined with Cache Manifests, HTML5 provides all the tools necessary for building offline applications.

\subsection{Web Storage}
The simplest API is the \emph{localStorage} standard defined in the W3C's Web Storage specification \cite{webstorage}.\\
It provides a key-value store accessible from JavaScript which can store string values for string keys.
Most browsers currently set a storage limit of 5 MB per site.
\emph{LocalStorage} is therefore only suitable for storing small volumes of data.\\
Another limitation is the interface which is synchronous. As JavaScript is single-threaded, every read or write operation will block the entire application.
Frequent or large-volume read/write operations can result in a bad user experience caused by a ``freezing'' user-interface.\\
\emph{LocalStorage} is currently supported by all major browsers including its mobile variants.

\subsection{Web SQL Database}
A much more advanced implementation is specified by the now deprecated \emph{Web SQL} standard \cite{websql}. It defines a relational database similar to Sqlite including SQL support.\\
The proposal was strongly opposed by the Mozilla Foundation who sees a SQL-based database as a bad fit for web applications \cite{mozilla_indexeddb}.\\
The standard was therefore only implemented by Google Chrome, Safari and Opera and their mobile counterparts in Android and iOS.\\
\emph{Web SQL} has been officially deprecated by the W3C and support by browsers is likely going to drop in the future.

\subsection{Indexed Database}
Instead of Web SQL the standard favored by the W3C and most browser vendors is \emph{IndexedDB}.\\
\emph{IndexedDB} defines a lower-level interface for storing key/value pairs and setting up custom indexes.
The While relatively simple, the API design is generic enough to cater for implementations of more complex databases on top.
It would for example be possible to implement a \emph{Web SQL} database using \emph{IndexedDB}.\\
IndexedDB supports storing large amounts of data and defines an asynchronous API.\\
Unfortunately the standard has not yet been implemented across all major browsers.
It is currently available in Mozilla Firefox, Google Chrome and Internet Explorer.
Safari support is still missing as well as support in the default Android and iOS browser.\\
Luckily most browsers who have not implemented IndexedDB yet, are still supporting Web SQL.
There is a polyfill available that implements an IndexedDB interface using Web SQL \cite{indexeddb_polyfill}. Application developers can therefore already base their work on the IndexedDB interface while browser vendors are catching up.

\subsection{Cache Manifests}
To truely work offline, an application has to make its static resources available locally as well.
The \emph{cache manifest} defined in the HTML standard gives you the right tool \cite{cache_manifests}. It allows you to define a local cache of all application resources like HTML, CSS, JavaScript code or other static files.\\
Flexible policies give fine-grained control over which resources should be available offline and which need network connection.
